import type { CancellationToken } from 'vscode';
import { ChatRole } from './openai';
import { PromptElement } from './promptElement';
import { BasePromptElementProps, PromptPiece, PromptSizing } from './types';
export type ChatMessagePromptElement = SystemMessage | UserMessage | AssistantMessage;
export declare function isChatMessagePromptElement(element: unknown): element is ChatMessagePromptElement;
export interface ChatMessageProps extends BasePromptElementProps {
    role?: ChatRole;
    name?: string;
}
export declare class BaseChatMessage extends PromptElement<ChatMessageProps> {
    render(): any;
}
/**
 * A {@link PromptElement} which can be rendered to an OpenAI system chat message.
 *
 * See {@link https://platform.openai.com/docs/api-reference/chat/create#chat-create-messages}
 */
export declare class SystemMessage extends BaseChatMessage {
    constructor(props: ChatMessageProps);
}
/**
 * A {@link PromptElement} which can be rendered to an OpenAI user chat message.
 *
 * See {@link https://platform.openai.com/docs/api-reference/chat/create#chat-create-messages}
 */
export declare class UserMessage extends BaseChatMessage {
    constructor(props: ChatMessageProps);
}
/**
 * A {@link PromptElement} which can be rendered to an OpenAI assistant chat message.
 *
 * See {@link https://platform.openai.com/docs/api-reference/chat/create#chat-create-messages}
 */
export declare class AssistantMessage extends BaseChatMessage {
    constructor(props: ChatMessageProps);
}
/**
 * A {@link PromptElement} which can be rendered to an OpenAI function chat message.
 *
 * See {@link https://platform.openai.com/docs/api-reference/chat/create#chat-create-messages}
 */
export declare class FunctionMessage extends BaseChatMessage {
    constructor(props: ChatMessageProps & {
        name: string;
    });
}
export interface TextChunkProps extends BasePromptElementProps {
    /**
     * If defined, the text chunk will potentially truncate its contents at the
     * last occurrence of the string or regular expression to ensure its content
     * fits within in token budget.
     *
     * {@see BasePromptElementProps} for options to control how the token budget
     * is allocated.
     */
    breakOn?: RegExp | string;
    /** A shortcut for setting {@link breakOn} to `/\s+/g` */
    breakOnWhitespace?: boolean;
}
/**
 * A chunk of single-line or multi-line text that is a direct child of a {@link ChatMessagePromptElement}.
 *
 * TextChunks can only have text literals or intrinsic attributes as children.
 * It supports truncating text to fix the token budget if passed a {@link TextChunkProps.tokenizer} and {@link TextChunkProps.breakOn} behavior.
 * Like other {@link PromptElement}s, it can specify `priority` to determine how it should be prioritized.
 */
export declare class TextChunk extends PromptElement<TextChunkProps, PromptPiece> {
    prepare(sizing: PromptSizing, _progress?: unknown, token?: CancellationToken): Promise<PromptPiece>;
    render(piece: PromptPiece): PromptPiece<any, any>;
}
export interface PrioritizedListProps extends BasePromptElementProps {
    /**
     * Priority of the list element.
     * All rendered elements in this list receive a priority that is offset from this value.
     */
    priority: number;
    /**
     * If `true`, assign higher priority to elements declared earlier in this list.
     */
    descending: boolean;
}
/**
 * A utility for assigning priorities to a list of prompt elements.
 */
export declare class PrioritizedList extends PromptElement<PrioritizedListProps> {
    render(): any;
}
