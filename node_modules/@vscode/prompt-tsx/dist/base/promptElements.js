"use strict";
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation and GitHub. All rights reserved.
 *--------------------------------------------------------------------------------------------*/
Object.defineProperty(exports, "__esModule", { value: true });
exports.PrioritizedList = exports.TextChunk = exports.FunctionMessage = exports.AssistantMessage = exports.UserMessage = exports.SystemMessage = exports.BaseChatMessage = exports.isChatMessagePromptElement = void 0;
const openai_1 = require("./openai");
const promptElement_1 = require("./promptElement");
function isChatMessagePromptElement(element) {
    return (element instanceof SystemMessage ||
        element instanceof UserMessage ||
        element instanceof AssistantMessage);
}
exports.isChatMessagePromptElement = isChatMessagePromptElement;
class BaseChatMessage extends promptElement_1.PromptElement {
    render() {
        return vscpp(vscppf, null, this.props.children);
    }
}
exports.BaseChatMessage = BaseChatMessage;
/**
 * A {@link PromptElement} which can be rendered to an OpenAI system chat message.
 *
 * See {@link https://platform.openai.com/docs/api-reference/chat/create#chat-create-messages}
 */
class SystemMessage extends BaseChatMessage {
    constructor(props) {
        props.role = openai_1.ChatRole.System;
        super(props);
    }
}
exports.SystemMessage = SystemMessage;
/**
 * A {@link PromptElement} which can be rendered to an OpenAI user chat message.
 *
 * See {@link https://platform.openai.com/docs/api-reference/chat/create#chat-create-messages}
 */
class UserMessage extends BaseChatMessage {
    constructor(props) {
        props.role = openai_1.ChatRole.User;
        super(props);
    }
}
exports.UserMessage = UserMessage;
/**
 * A {@link PromptElement} which can be rendered to an OpenAI assistant chat message.
 *
 * See {@link https://platform.openai.com/docs/api-reference/chat/create#chat-create-messages}
 */
class AssistantMessage extends BaseChatMessage {
    constructor(props) {
        props.role = openai_1.ChatRole.Assistant;
        super(props);
    }
}
exports.AssistantMessage = AssistantMessage;
const WHITESPACE_RE = /\s+/g;
/**
 * A {@link PromptElement} which can be rendered to an OpenAI function chat message.
 *
 * See {@link https://platform.openai.com/docs/api-reference/chat/create#chat-create-messages}
 */
class FunctionMessage extends BaseChatMessage {
    constructor(props) {
        props.role = openai_1.ChatRole.Function;
        super(props);
    }
}
exports.FunctionMessage = FunctionMessage;
/**
 * A chunk of single-line or multi-line text that is a direct child of a {@link ChatMessagePromptElement}.
 *
 * TextChunks can only have text literals or intrinsic attributes as children.
 * It supports truncating text to fix the token budget if passed a {@link TextChunkProps.tokenizer} and {@link TextChunkProps.breakOn} behavior.
 * Like other {@link PromptElement}s, it can specify `priority` to determine how it should be prioritized.
 */
class TextChunk extends promptElement_1.PromptElement {
    async prepare(sizing, _progress, token) {
        const breakOn = this.props.breakOnWhitespace ? WHITESPACE_RE : this.props.breakOn;
        if (!breakOn) {
            return vscpp(vscppf, null, this.props.children);
        }
        let fullText = '';
        const intrinsics = [];
        for (const child of this.props.children || []) {
            if (child && typeof child === 'object') {
                if (typeof child.ctor !== 'string') {
                    throw new Error('TextChunk children must be text literals or intrinsic attributes.');
                }
                else if (child.ctor === 'br') {
                    fullText += '\n';
                }
                else {
                    intrinsics.push(child);
                }
            }
            else if (child != null) {
                fullText += child;
            }
        }
        const text = await getTextContentBelowBudget(sizing, breakOn, fullText, token);
        return vscpp(vscppf, null,
            intrinsics,
            text);
    }
    render(piece) {
        return piece;
    }
}
exports.TextChunk = TextChunk;
async function getTextContentBelowBudget(sizing, breakOn, fullText, cancellation) {
    if (breakOn instanceof RegExp) {
        if (!breakOn.global) {
            throw new Error(`\`breakOn\` expression must have the global flag set (got ${breakOn})`);
        }
        breakOn.lastIndex = 0;
    }
    let outputText = '';
    let lastIndex = -1;
    while (lastIndex < fullText.length) {
        let index;
        if (typeof breakOn === 'string') {
            index = fullText.indexOf(breakOn, lastIndex === -1 ? 0 : lastIndex + breakOn.length);
        }
        else {
            index = breakOn.exec(fullText)?.index ?? -1;
        }
        if (index === -1) {
            index = fullText.length;
        }
        const next = outputText + fullText.slice(Math.max(0, lastIndex), index);
        if (await sizing.countTokens(next, cancellation) > sizing.tokenBudget) {
            return outputText;
        }
        outputText = next;
        lastIndex = index;
    }
    return outputText;
}
/**
 * A utility for assigning priorities to a list of prompt elements.
 */
class PrioritizedList extends promptElement_1.PromptElement {
    render() {
        const children = this.props.children;
        if (!children) {
            return;
        }
        return (vscpp(vscppf, null, children.map((child, i) => {
            child.props ?? (child.props = {});
            child.props.priority = this.props.descending
                ? // First element in array of children has highest priority
                    this.props.priority - i
                : // Last element in array of children has highest priority
                    this.props.priority - children.length + i;
            return child;
        })));
    }
}
exports.PrioritizedList = PrioritizedList;
